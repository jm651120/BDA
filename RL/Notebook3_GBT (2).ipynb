{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f7b05ba-a594-4186-a3f0-bb9ac7ab1d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nDistribuiÃ§Ã£o apÃ³s balanceamento:\n+-----+------+\n|label| count|\n+-----+------+\n|  0.0|674488|\n|  1.0|125441|\n+-----+------+\n\n\nðŸ” Threshold Search (para F1 classe 1):\nThreshold = 0.05 | F1 (classe 1): 0.0841\nThreshold = 0.10 | F1 (classe 1): 0.0841\nThreshold = 0.15 | F1 (classe 1): 0.0841\nThreshold = 0.20 | F1 (classe 1): 0.0841\nThreshold = 0.25 | F1 (classe 1): 0.0841\nThreshold = 0.30 | F1 (classe 1): 0.0841\nThreshold = 0.35 | F1 (classe 1): 0.0841\nThreshold = 0.40 | F1 (classe 1): 0.0841\nThreshold = 0.45 | F1 (classe 1): 0.0841\nThreshold = 0.50 | F1 (classe 1): 0.0841\nThreshold = 0.55 | F1 (classe 1): 0.0837\nThreshold = 0.60 | F1 (classe 1): 0.0030\nThreshold = 0.65 | F1 (classe 1): 0.0007\nThreshold = 0.70 | F1 (classe 1): 0.0000\nThreshold = 0.75 | F1 (classe 1): 0.0000\nThreshold = 0.80 | F1 (classe 1): 0.0000\nThreshold = 0.85 | F1 (classe 1): 0.0000\nThreshold = 0.90 | F1 (classe 1): 0.0000\n\nâœ… Melhor Threshold Encontrado: 0.10 com F1 da classe 1 = 0.0841\n\nConfusion Matrix (com melhor threshold):\n[[1.32633e+05 5.81288e+05]\n [1.00000e+00 2.66970e+04]]\n\nðŸŽ¯ MÃ©tricas finais com melhor threshold:\nPrecision classe 1: 0.0439\nRecall classe 1:    1.0000\nF1 classe 1:        0.0841\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Carregar dados\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Balanceamento leve (undersample da classe maioritÃ¡ria)\n",
    "minority_df = train_ready.filter(col(\"label\") == 1)\n",
    "majority_df = train_ready.filter(col(\"label\") != 1)\n",
    "train_balanced = majority_df.sample(False, 0.4, seed=42).union(minority_df)\n",
    "\n",
    "print(\"\\nDistribuiÃ§Ã£o apÃ³s balanceamento:\")\n",
    "train_balanced.groupBy(\"label\").count().show()\n",
    "\n",
    "# Treinar modelo GBT sem class weights\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=20,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n",
    "model = gbt.fit(train_balanced)\n",
    "\n",
    "# InferÃªncia no conjunto de validaÃ§Ã£o\n",
    "val_preds = model.transform(val_ready)\n",
    "\n",
    "# Aplicar threshold manual conhecido\n",
    "def apply_threshold(df, threshold):\n",
    "    predict_udf = udf(lambda prob: float(1.0) if prob[1] > threshold else float(0.0), DoubleType())\n",
    "    return df.withColumn(\"adjusted_prediction\", predict_udf(col(\"probability\")))\n",
    "\n",
    "# âœ… Threshold conhecido\n",
    "best_threshold = 0.30\n",
    "val_preds_adjusted = apply_threshold(val_preds, best_threshold)\n",
    "\n",
    "# AvaliaÃ§Ã£o final\n",
    "final_rdd = val_preds_adjusted.select(\"adjusted_prediction\", \"label\").rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "metrics = MulticlassMetrics(final_rdd)\n",
    "\n",
    "print(f\"\\nâœ… AvaliaÃ§Ã£o com Threshold = {best_threshold:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "print(\"\\nðŸŽ¯ MÃ©tricas finais:\")\n",
    "print(f\"Precision classe 1: {metrics.precision(1.0):.4f}\")\n",
    "print(f\"Recall classe 1:    {metrics.recall(1.0):.4f}\")\n",
    "print(f\"F1 classe 1:        {metrics.fMeasure(1.0):.4f}\")\n",
    "\n",
    "# Guardar modelo final\n",
    "model.write().overwrite().save(\"/FileStore/models/gbt_top10_no_weights\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_GBT",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
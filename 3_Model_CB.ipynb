{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b22023e-baee-44a2-ae28-14c579c1abf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Parameters Found: {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# need to add a new library to the cluster, using PyPI add catboost\n",
    "#####################################\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Load top-k features slicer model\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Apply slicer to datasets\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk = slicer_model.transform(val_ready)\n",
    "\n",
    "# Light undersampling for grid search (10%)\n",
    "minority_df = train_topk.filter(col(\"label\") == 1)\n",
    "majority_df = train_topk.filter(col(\"label\") != 1)\n",
    "train_balanced = majority_df.sample(False, 0.1, seed=42).union(minority_df)\n",
    "\n",
    "# Convert VectorUDT to list\n",
    "def vector_to_array(v):\n",
    "    if isinstance(v, DenseVector) or isinstance(v, SparseVector):\n",
    "        return v.toArray().tolist()\n",
    "    return v\n",
    "\n",
    "vector_to_array_udf = udf(vector_to_array, ArrayType(DoubleType()))\n",
    "\n",
    "train_array = train_balanced.withColumn(\"features_array\", vector_to_array_udf(\"features_topK\"))\n",
    "val_array = val_topk.withColumn(\"features_array\", vector_to_array_udf(\"features_topK\"))\n",
    "\n",
    "# Convert to Pandas\n",
    "train_pd = train_array.select(\"features_array\", \"label\").toPandas()\n",
    "val_pd = val_array.select(\"features_array\", \"label\").toPandas()\n",
    "\n",
    "X_train = pd.DataFrame(train_pd[\"features_array\"].tolist())\n",
    "y_train = train_pd[\"label\"]\n",
    "\n",
    "X_val = pd.DataFrame(val_pd[\"features_array\"].tolist())\n",
    "y_val = val_pd[\"label\"]\n",
    "\n",
    "# Compute class weights\n",
    "label_counts = y_train.value_counts().to_dict()\n",
    "total = sum(label_counts.values())\n",
    "class_weights = {label: total / count for label, count in label_counts.items()}\n",
    "class_weights_list = [class_weights[i] for i in sorted(class_weights)]\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "params = {\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'iterations': [100, 200],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "}\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    loss_function='MultiClass',\n",
    "    class_weights=class_weights_list,\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(cat, param_grid=params, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "model = grid.best_estimator_\n",
    "print(\" Best Parameters Found:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6abe4d0c-6b80-427a-8368-b6b90faa6d95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search for class weights...\nclass_weights=[1, 11] | F1-macro: 0.4909 | Balanced Acc: 0.5000 | Recall-macro: 0.5000 | Pred distribution: Counter({0.0: 740542, 1.0: 77})\nclass_weights=[1, 12] | F1-macro: 0.4913 | Balanced Acc: 0.5001 | Recall-macro: 0.5001 | Pred distribution: Counter({0.0: 740373, 1.0: 246})\nclass_weights=[1, 13] | F1-macro: 0.4917 | Balanced Acc: 0.5002 | Recall-macro: 0.5002 | Pred distribution: Counter({0.0: 740112, 1.0: 507})\nclass_weights=[1, 14] | F1-macro: 0.4942 | Balanced Acc: 0.5007 | Recall-macro: 0.5007 | Pred distribution: Counter({0.0: 738365, 1.0: 2254})\nclass_weights=[1, 15] | F1-macro: 0.4957 | Balanced Acc: 0.5007 | Recall-macro: 0.5007 | Pred distribution: Counter({0.0: 736230, 1.0: 4389})\nclass_weights=[1, 16] | F1-macro: 0.5015 | Balanced Acc: 0.5021 | Recall-macro: 0.5021 | Pred distribution: Counter({0.0: 725974, 1.0: 14645})\nclass_weights=[1, 17] | F1-macro: 0.4864 | Balanced Acc: 0.5159 | Recall-macro: 0.5159 | Pred distribution: Counter({0.0: 627162, 1.0: 113457})\nclass_weights=[1, 18] | F1-macro: 0.3480 | Balanced Acc: 0.5617 | Recall-macro: 0.5617 | Pred distribution: Counter({1.0: 411965, 0.0: 328654})\nclass_weights=[1, 19] | F1-macro: 0.2590 | Balanced Acc: 0.5804 | Recall-macro: 0.5804 | Pred distribution: Counter({1.0: 538331, 0.0: 202288})\n\n Best result:\nClass weights: [1, 16]\nF1-macro: 0.5015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, recall_score\n",
    "from collections import Counter\n",
    "\n",
    "# New undersampling: 80% of the majority class\n",
    "minority_df = train_topk.filter(col(\"label\") == 1)\n",
    "majority_df = train_topk.filter(col(\"label\") != 1)\n",
    "train_balanced = majority_df.sample(False, 0.8, seed=42).union(minority_df)\n",
    "\n",
    "# Repeat transformation and conversion to pandas\n",
    "train_array = train_balanced.withColumn(\"features_array\", vector_to_array_udf(\"features_topK\"))\n",
    "train_pd = train_array.select(\"features_array\", \"label\").toPandas()\n",
    "\n",
    "X_train = pd.DataFrame(train_pd[\"features_array\"].tolist())\n",
    "y_train = train_pd[\"label\"]\n",
    "\n",
    "# Manual Grid Search for Class Weights\n",
    "best_score = -1\n",
    "best_weights = None\n",
    "best_model = None\n",
    "\n",
    "weight_options = [11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "results = []\n",
    "\n",
    "print(\"Starting grid search for class weights...\")\n",
    "\n",
    "for w1 in weight_options:\n",
    "    class_weights_list = [1, w1]  # Class 0 → 1, Class 1 → w1\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        depth=8,\n",
    "        iterations=200,\n",
    "        learning_rate=0.1,\n",
    "        l2_leaf_reg=1,\n",
    "        loss_function='MultiClass',\n",
    "        class_weights=class_weights_list,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=0,\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.array(y_pred).ravel()\n",
    "    \n",
    "    unique_preds = np.unique(y_pred)\n",
    "    if len(unique_preds) < 2:\n",
    "        print(f\"Ignored class_weights={class_weights_list} → only predicted class {unique_preds[0]}\")\n",
    "        continue\n",
    "    \n",
    "    score_f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    score_bal = balanced_accuracy_score(y_val, y_pred)\n",
    "    score_rec = recall_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    results.append((class_weights_list, score_f1, score_bal, score_rec, model))\n",
    "    \n",
    "    print(f\"class_weights={class_weights_list} | F1-macro: {score_f1:.4f} | Balanced Acc: {score_bal:.4f} | Recall-macro: {score_rec:.4f} | Pred distribution: {Counter(y_pred)}\")\n",
    "\n",
    "    if score_f1 > best_score:\n",
    "        best_score = score_f1\n",
    "        best_weights = class_weights_list\n",
    "        best_model = model\n",
    "\n",
    "print(\"\\n Best result:\")\n",
    "print(f\"Class weights: {best_weights}\")\n",
    "print(f\"F1-macro: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbdb59dd-fba7-47b2-bf0c-6ad5db5d6f80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix:\n[[699912  14009]\n [ 26062    636]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n         0.0     0.9641    0.9804    0.9722    713921\n         1.0     0.0434    0.0238    0.0308     26698\n\n    accuracy                         0.9459    740619\n   macro avg     0.5038    0.5021    0.5015    740619\nweighted avg     0.9309    0.9459    0.9382    740619\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "print(\" Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "# Save the model\n",
    "os.makedirs(\"/dbfs/FileStore/models/\", exist_ok=True)\n",
    "best_model.save_model(\"/dbfs/FileStore/models/cb_top10_model_best_weights.cbm\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_CB",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}